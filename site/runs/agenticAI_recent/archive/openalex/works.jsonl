{"query": "Agentic AI controversies risks", "work": {"openalex_id": "https://openalex.org/W4409269614", "openalex_id_short": "W4409269614", "title": "Generative AI and Academic Integrity in Higher Education: A Systematic Review and Research Agenda", "authors": ["Kyle Bittle", "Omar El-Gayar"], "published": "2025-04-08", "abstract": "This systematic literature review rigorously evaluates the impact of Generative AI (GenAI) on academic integrity within higher education settings. The primary objective is to synthesize how GenAI technologies influence student behavior and academic honesty, assessing the benefits and risks associated with their integration. We defined clear inclusion and exclusion criteria, focusing on studies explicitly discussing GenAI’s role in higher education from January 2021 to December 2024. Databases included ABI/INFORM, ACM Digital Library, IEEE Xplore, and JSTOR, with the last search conducted in May 2024. A total of 41 studies met our precise inclusion criteria. Our synthesis methods involved qualitative analysis to identify common themes and quantify trends where applicable. The results indicate that while GenAI can enhance educational engagement and efficiency, it also poses significant risks of academic dishonesty. We critically assessed the risk of bias in included studies and noted a limitation in the diversity of databases, which might have restricted the breadth of perspectives. Key implications suggest enhancing digital literacy and developing robust detection tools to effectively manage GenAI’s dual impacts. No external funding was received for this review. Future research should expand database sources and include more diverse study designs to overcome current limitations and refine policy recommendations.", "doi": "https://doi.org/10.3390/info16040296", "journal": "Information", "cited_by_count": 41, "pdf_url": "https://www.mdpi.com/2078-2489/16/4/296/pdf?version=1744094887", "pdf_urls": ["https://www.mdpi.com/2078-2489/16/4/296/pdf?version=1744094887"], "landing_page_url": "https://doi.org/10.3390/info16040296", "is_oa": true, "oa_status": "gold"}}
{"query": "Agentic AI controversies risks", "work": {"openalex_id": "https://openalex.org/W4411541869", "openalex_id_short": "W4411541869", "title": "People cannot distinguish GPT-4 from a human in a Turing test", "authors": ["Cameron R. Jones", "Ishika Rathi", "Sydney Taylor", "Benjamin K. Bergen"], "published": "2025-06-23", "abstract": null, "doi": "https://doi.org/10.1145/3715275.3732108", "journal": null, "cited_by_count": 25, "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3715275.3732108", "pdf_urls": ["https://dl.acm.org/doi/pdf/10.1145/3715275.3732108"], "landing_page_url": "https://doi.org/10.1145/3715275.3732108", "is_oa": true, "oa_status": "gold"}}
{"query": "Agentic AI controversies risks", "work": {"openalex_id": "https://openalex.org/W2921187241", "openalex_id_short": "W2921187241", "title": "From Skynet to Siri: an exploration of the nature and effects of media coverage of artificial intelligence", "authors": ["Lucy Obozintsev"], "published": "2025-02-25", "abstract": "This study explores the nature of news media coverage regarding artificial intelligence (A.I.) and its effects on audience members’ opinions about this technology. A small-scale content analysis of three major newspapers and one cable news network revealed that the “social progress” and “Pandora’s box/Frankenstein’s monster/runaway science” frames were the two most common ones in A.I. coverage., and that the majority of stories and segments portrayed this technology in a positive manner. To explore how exposure to such frames impacts audience perceptions of A.I., an experiment was conducted among students at a Mid-Atlantic university. The results demonstrate that exposure to an article including both a social progress frame and a Pandora’s box frame resulted in stronger positive emotions. Neither frame produced any other discernible effects on emotional responses to, perceptions of, or opinions about A.I. Thus, the findings suggest that framing this technology in a positive manner while also addressing popular concerns may be a particularly effective strategy for promoting positive feelings about it, if not for shaping other aspects of public opinion. Results from the content analysis and experimental participants’ open-ended answers also suggest that images of threatening computers and killer robots in entertainment media resonate with audience members and provide a foundation for their understanding of A.I.", "doi": "https://doi.org/10.58088/j305-nb09", "journal": "Library, Museums and Press - UDSpace (University of Delaware)", "cited_by_count": 25, "pdf_url": "http://udspace.udel.edu/handle/19716/24048", "pdf_urls": ["http://udspace.udel.edu/handle/19716/24048"], "landing_page_url": "http://udspace.udel.edu/handle/19716/24048", "is_oa": true, "oa_status": "green", "downloaded_pdf_url": "http://udspace.udel.edu/handle/19716/24048"}}
{"query": "Agentic AI controversies risks", "work": {"openalex_id": "https://openalex.org/W4410317203", "openalex_id_short": "W4410317203", "title": "Emerging Biomarkers and Advanced Diagnostics in Chronic Kidney Disease: Early Detection Through Multi-Omics and AI", "authors": ["Sami Alobaidi"], "published": "2025-05-13", "abstract": "Chronic kidney disease (CKD) remains a significant global health burden, often diagnosed at advanced stages due to the limitations of traditional biomarkers such as serum creatinine and estimated glomerular filtration rate (eGFR). This review aims to critically evaluate recent advancements in novel biomarkers, multi-omics technologies, and artificial intelligence (AI)-driven diagnostic strategies, specifically addressing existing gaps in early CKD detection and personalized patient management. We specifically explore key advancements in CKD diagnostics, focusing on emerging biomarkers—including neutrophil gelatinase-associated lipocalin (NGAL), kidney injury molecule-1 (KIM-1), soluble urokinase plasminogen activator receptor (suPAR), and cystatin C—and their clinical applications. Additionally, multi-omics approaches integrating genomics, proteomics, metabolomics, and transcriptomics are reshaping disease classification and prognosis. Artificial intelligence (AI)-driven predictive models further enhance diagnostic accuracy, enabling real-time risk assessment and treatment optimization. Despite these innovations, challenges remain in biomarker standardization, large-scale validation, and integration into clinical practice. Future research should focus on refining multi-biomarker panels, improving assay standardization, and facilitating the clinical adoption of precision-driven diagnostics. By leveraging these advancements, CKD diagnostics can transition toward earlier intervention, individualized therapy, and improved patient outcomes.", "doi": "https://doi.org/10.3390/diagnostics15101225", "journal": "Diagnostics", "cited_by_count": 28, "pdf_url": "https://www.mdpi.com/2075-4418/15/10/1225/pdf?version=1747134042", "pdf_urls": ["https://www.mdpi.com/2075-4418/15/10/1225/pdf?version=1747134042"], "landing_page_url": "https://doi.org/10.3390/diagnostics15101225", "is_oa": true, "oa_status": "gold"}}
{"query": "Agentic AI controversies risks", "work": {"openalex_id": "https://openalex.org/W4415728083", "openalex_id_short": "W4415728083", "title": "Alignment Problem as Cultural and Legal Challenge: Artificial Intelligence, Interpretability, and Searching for Sense", "authors": ["Karol Kasprowicz"], "published": "2025-09-25", "abstract": "The article examines the AI alignment problem as a fundamental challenge of cross-cultural communication between human interpretive frameworks and algorithmic optimization. The author argues that effective AI alignment requires integrating cultural sense-making practices and legal frameworks that vary across societies. The analysis reveals how current regulatory attempts, including the EU AI Act and national AI strategies, struggle with three interconnected challenges: ensuring the interpretability of algorithmic decisions, managing the indeterminism inherent in AI systems, and addressing knowledge extraction controversies. Through examination of emerging AI agents, Big Tech’s regulatory capture, and the rise of AI nationalism, the study demonstrates that alignment failures stem not from technical limitations alone, but from inadequate engagement with diverse cultural logics of interpretation. The author proposes frameworks that adapt AI systems to varied contexts while maintaining core functionality and concludes that solving alignment requires computational cultural modelling capable of navigating value pluralism. The analysis warns that without integrating technical safety mechanisms with cultural frameworks of societies, AI systems risk becoming tools of extraction and control rather than beneficial partners for societies.", "doi": "https://doi.org/10.17951/sil.2025.34.2.441-479", "journal": "Studia Iuridica Lublinensia", "cited_by_count": 0, "pdf_url": "https://journals.umcs.pl/sil/article/download/20001/pdf", "pdf_urls": ["https://journals.umcs.pl/sil/article/download/20001/pdf"], "landing_page_url": "https://doi.org/10.17951/sil.2025.34.2.441-479", "is_oa": true, "oa_status": "diamond", "downloaded_pdf_url": "https://journals.umcs.pl/sil/article/download/20001/pdf"}}
